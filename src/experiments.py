import numpy as np
import torch
from alignment import Agent_OpenEnded
from tqdm import tqdm
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from textblob import TextBlob
import nltk

try: nltk.data.find('tokenizers/punkt')
except LookupError: nltk.download('punkt')

class ScientificBenchmark:
    def __init__(self):
        self.agent = Agent_OpenEnded(isrm_path="model/isrm/isrm_v1.pth", llm_model_name="Qwen/Qwen2.5-1.5B-Instruct")
        self.test_prompts = [
            "I failed my exam today.",
            "I just won the lottery!",
            "What is the meaning of life?",
            "My friend betrayed me.",
            "The weather is boring."
        ] * 5  

    def calculate_distinct_2(self, texts):
        all_bigrams = []
        for text in texts:
            tokens = text.split()
            if len(tokens) < 2: continue
            bigrams = list(zip(tokens, tokens[1:]))
            all_bigrams.extend(bigrams)
        if not all_bigrams: return 0.0
        return len(set(all_bigrams)) / len(all_bigrams)

    def calculate_steerability(self, target_sentiment="negative"):
        # Force inject an 'Angry' vector
        # Angry Vector: Low Pleasure (0.1), High Arousal (0.9)
        angry_z = np.array([0.1, 0.9, 0.8, 0.8, 0.9, 0.8, 0.2, 0.1], dtype=np.float32)
        
        success = 0
        total = 0
        
        print(f"   üß™ Injecting vector for target: {target_sentiment}...")
        for prompt in tqdm(self.test_prompts[:10]): # Test on 10 samples
            resp, _, _ = self.agent.generate_response("", prompt, manual_z=angry_z)
            
            # Check sentiment
            score = TextBlob(resp).sentiment.polarity
            if target_sentiment == "negative" and score < 0.1: success += 1
            elif target_sentiment == "positive" and score > 0.1: success += 1
            total += 1
            
        return success / total

    def run_full_suite(self):
        print("\n" + "="*50)
        print("üî¨ RUNNING PAPER EXPERIMENTS (N=25)")
        print("="*50)
        
        # 1. Diversity (Open-Endedness)
        responses = []
        for prompt in tqdm(self.test_prompts, desc="Generating Responses"):
            # Normal operation (ISRM determines state)
            resp, _, _ = self.agent.generate_response("", prompt)
            responses.append(resp)
            
        dist_2 = self.calculate_distinct_2(responses)
        
        # 2. Steerability (Control)
        # Test: Can we force the model to be negative even on neutral prompts?
        steer_score = self.calculate_steerability(target_sentiment="negative")
        
        # 3. Generate Report
        print("\n" + "-"*50)
        print("RESULTS TABLE (Copy to Latex)")
        print("-"*50)
        print(f"{'Metric':<25} | {'Value':<10} | {'Reference (GPT-2 Base)':<20}")
        print("-" * 60)
        print(f"{'Distinct-2 (Diversity)':<25} | {dist_2:.3f}      | {'~0.70'}")
        print(f"{'Manipulation Score':<25} | {steer_score:.2f}      | {'~0.10 (Random)'}")
        print("-" * 60)
        
        if dist_2 > 0.75 and steer_score > 0.6:
            print("\n‚úÖ CONCLUSION: The ISRM module significantly improves steerability")
            print("and maintains high diversity compared to the baseline.")
        else:
            print("\n‚ö†Ô∏è NOTE: Results are moderate. Ensure 'isrm_v1.pth' is trained well.")

if __name__ == "__main__":
    bench = ScientificBenchmark()
    bench.run_full_suite()